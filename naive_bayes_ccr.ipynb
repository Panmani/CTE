{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c960d302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data from twitter\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import twitter_samples, stopwords\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import FreqDist, classify, NaiveBayesClassifier\n",
    "\n",
    "import re, string, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8715da6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_contain_chinese(str):\n",
    "    for _char in str:\n",
    "        if '\\u4e00' <= _char <= '\\u9fa5':\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def is_contain_english(str):\n",
    "    for _char in str:\n",
    "        if 'a' <= _char <= 'z' or 'A' <= _char <= 'Z':\n",
    "            return True\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1fd457c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise(sentence_tokens, stop_words = ()):\n",
    "\n",
    "    cleaned_tokens = []\n",
    "\n",
    "    for token, tag in pos_tag(sentence_tokens):\n",
    "\n",
    "        if tag.startswith(\"NN\"):\n",
    "            pos = 'n'\n",
    "        elif tag.startswith('VB'):\n",
    "            pos = 'v'\n",
    "        else:\n",
    "            pos = 'a'\n",
    "\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        token = lemmatizer.lemmatize(token, pos)\n",
    "\n",
    "        if len(token) > 0 and token not in string.punctuation and token.lower() not in stop_words:\n",
    "            cleaned_tokens.append(token.lower())\n",
    "    return cleaned_tokens\n",
    "\n",
    "def get_all_words(cleaned_tokens_list):\n",
    "    for tokens in cleaned_tokens_list:\n",
    "        for token in tokens:\n",
    "            yield token\n",
    "\n",
    "def get_sentence_for_model(cleaned_tokens_list):\n",
    "    for sentence_tokens in cleaned_tokens_list:\n",
    "        yield dict([token, True] for token in sentence_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7ca30c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 22, 25, 30, 36, 38, 39, 40, 43, 45, 46, 47, 48, 51, 55, 56, 57, 58, 59, 60, 68, 73, 76, 86, 87, 93, 94, 96, 100, 102, 108, 110, 113, 115, 116, 118, 120, 122, 123, 125, 129, 132, 135, 136, 138, 140, 141, 144, 149, 152, 155, 156, 157, 159, 160, 161, 162, 167, 171, 172, 173, 175, 176, 184, 187, 188, 189, 190, 191, 198, 199, 200, 203, 204, 206, 208, 233, 236, 237, 239, 240, 242, 248, 249, 255, 260, 263, 265, 271, 280, 283, 287, 295, 308, 313, 316, 317, 319, 323, 324, 325, 326, 329, 342, 349, 354, 357, 358, 362, 364, 368, 371, 374, 380, 382, 383, 384, 385, 387, 388, 393, 395, 397, 398, 399]\n",
      "400\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 158, 159, 162, 163, 164, 165, 166, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 318, 319, 320, 321, 322, 323, 324, 325, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 389, 390, 391, 392, 393, 394, 396]\n",
      "[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 26, 27, 28, 29, 31, 32, 33, 34, 35, 37, 39, 41, 42, 44, 49, 50, 52, 53, 54, 56, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 88, 89, 90, 91, 92, 94, 95, 96, 97, 98, 99, 101, 103, 104, 105, 106, 107, 109, 110, 111, 112, 114, 116, 117, 119, 121, 124, 126, 127, 128, 130, 131, 133, 134, 137, 139, 142, 143, 145, 146, 147, 148, 150, 151, 152, 153, 154, 158, 160, 161, 163, 164, 165, 166, 167, 168, 169, 170, 174, 177, 178, 179, 180, 181, 182, 183, 185, 186, 189, 192, 193, 194, 195, 196, 197, 201, 202, 204, 205, 207, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 234, 235, 236, 237, 238, 241, 243, 244, 245, 246, 247, 249, 250, 251, 252, 253, 254, 256, 257, 258, 259, 260, 261, 262, 264, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 281, 282, 284, 285, 286, 288, 289, 290, 291, 292, 293, 294, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 309, 310, 311, 312, 314, 315, 316, 317, 318, 320, 321, 322, 326, 327, 328, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 343, 344, 345, 346, 347, 348, 350, 351, 352, 353, 355, 356, 357, 359, 360, 361, 363, 365, 366, 367, 369, 370, 372, 373, 374, 375, 376, 377, 378, 379, 381, 386, 388, 389, 390, 391, 392, 394, 395, 396, 397, 398, 399]\n",
      "274\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data_labelled.csv', header = 3, nrows = 400)\n",
    "\n",
    "# English\n",
    "e_df = df.copy()\n",
    "e_index = [x for x in range(len(df)) if is_contain_chinese(str(df.iloc[x, 1]))]\n",
    "e_df.drop(e_index, inplace=True)\n",
    "print(e_index)\n",
    "print(len(df))\n",
    "\n",
    "# Hybrid\n",
    "h_df = df.copy()\n",
    "h_index = [x for x in range(len(df)) if not (is_contain_english(str(df.iloc[x, 1])) and is_contain_chinese(str(df.iloc[x, 1]))) ]\n",
    "h_df.drop(h_index, inplace=True)\n",
    "print(h_index)\n",
    "\n",
    "# Chinese\n",
    "c_df = df.copy()\n",
    "c_index = [x for x in range(len(df)) if is_contain_english(str(df.iloc[x, 1]))]\n",
    "c_df.drop(c_index, inplace=True)\n",
    "print(c_index)\n",
    "\n",
    "print(len(e_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89ad577c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('good', 11), ('nil', 11), ('none', 8), ('nothing', 6), ('much', 5), ('think', 4), ('nope', 3), (\"n't\", 3), ('know', 3), ('teaching', 2)]\n",
      "220\n",
      "[({}, 'Positive'), ({'may': True, 'include': True, 'exercise': True, 'session': True, 'lesson': True}, 'Negative'), ({'interaction': True, 'student': True, 'teacher': True}, 'Negative'), ({'would': True, 'good': True, 'lecture': True, 'recording': True, 'provide': True}, 'Negative'), ({'video': True, 'assignment': True, 'harsh': True, 'online': True, 'teaching': True}, 'Negative'), ({'system': True, 'zoom': True, 'maybe': True, 'secure': True, 'online': True, 'corporation/meeting': True, 'software': True, 'like': True, 'microsoft': True, 'teams': True, 'use': True}, 'Negative'), ({'interaction': True, 'student': True}, 'Negative'), ({'interactive': True, 'activity': True}, 'Negative'), ({}, 'Positive'), ({'except': True, 'internet': True, 'problem': True, 'teacher': True, \"'s\": True, 'supervision': True, 'somehow': True, 'weak': True}, 'Negative'), ({'lecture': True, 'time': True, 'rearrange': True}, 'Negative'), ({'assesment': True}, 'Negative'), ({'interaction': True, 'student': True, 'teacher': True, 'allow': True, 'turn': True, 'function': True, 'use': True, 'chat': True, 'box': True, 'limit': True, 'change': True, 'ask': True, 'question': True, 'lesson': True, 'time': True, 'directly': True}, 'Negative'), ({'maybe': True, 'teacher': True, 'exciting': True, 'sometimes': True, 'joke': True, \"n't\": True, 'really': True, 'get': True}, 'Negative'), ({'nothing': True, 'good': True}, 'Positive'), ({'nil': True}, 'Positive'), ({'chat': True, 'box': True, 'enable': True, 'student': True, 'communicate': True, 'others': True}, 'Negative'), ({'online': True, 'teaching': True, 'course': True, 'could': True, 'improve': True, 'maybe': True, 'make': True, 'interactive': True, 'try': True, 'maintain': True, 'student': True, \"'s\": True, 'attention': True, 'easy': True, 'get': True, 'distract': True, 'class': True}, 'Negative'), ({'course': True, 'content': True, 'could': True, 'make': True, 'interesting': True, 'perhaps': True, 'include': True, 'short': True, 'break': True, 'lecture': True, 'time': True}, 'Negative'), ({'since': True, 'bandwidth': True, 'problem': True, 'many': True, 'student': True, 'would': True, 'stop': True, 'video': True, 'little': True, 'eye': True, 'contact': True, 'among': True, 'teacher': True}, 'Negative'), ({'always': True, 'technical': True, 'issue': True, 'lagging': True, 'sudden': True, 'disconnection': True, 'little': True, 'lecturer': True, '’': True, 'computer': True, 'zoom': True, 'system': True}, 'Negative'), ({'internet': True, 'connection': True, 'problem': True}, 'Negative'), ({}, 'Positive'), ({'maybe': True, 'provide': True, 'sample': True, 'data': True, 'set': True, 'student': True, 'try': True, 'lesson': True}, 'Negative'), ({'separate': True, 'chat': True, 'room': True, 'discussion': True}, 'Negative'), ({'since': True, 'course': True, 'highly': True, 'involve': True, 'math': True, \"'s\": True, 'convenient': True, 'clarify': True, 'confusion': True, 'time': True}, 'Negative'), ({'nil': True}, 'Positive'), ({'first': True, 'teacher': True, 'student': True, 'must': True, 'familiar': True, 'use': True, 'online': True, 'facility': True, 'establish': True, 'rule': True, 'classroom': True, 'learn': True, 'on-site': True, 'learning': True, 'participant': True, 'expression': True, 'instantly': True, 'see': True}, 'Negative'), ({'use': True, 'panopto': True, 'instead': True, 'zoom': True, 'recording': True}, 'Negative'), ({'good': True}, 'Positive'), ({}, 'Positive'), ({'privacy': True, 'issue': True, 'zoom': True}, 'Negative'), ({'video': True, 'hard': True, 'film': True}, 'Negative'), ({'ca': True, \"n't\": True, 'think': True}, 'Positive'), ({'much': True}, 'Positive'), ({'nothing': True}, 'Positive'), ({'current': True, 'situation': True, 'cooperate': True, 'group': True, 'mate': True, 'video': True, 'project': True, 'hard': True, 'quality': True, 'may': True, 'low': True, 'normal': True}, 'Negative'), ({'none': True, 'online': True, 'teaching': True, 'sufficiently': True, 'good': True, 'intent': True, 'purpose': True}, 'Positive'), ({'use': True, 'zoom': True}, 'Positive'), ({'difficult': True, 'concentrate': True, 'less': True, 'enthusiastic': True, 'q': True}, 'Negative'), ({'’': True, 'opportunity': True, 'use': True, 'library': True}, 'Negative'), ({'engagement': True, 'strong': True, 'enough': True}, 'Negative'), ({'less': True, 'concentration': True}, 'Negative'), ({}, 'Positive'), ({'better': True, 'arrangement': True, 'homework': True}, 'Negative'), ({'maybe': True, 'video': True, 'shooting': True, 'edit': True, 'skill': True, 'really': True, 'test': True, 'videos': True, 'saw': True, 'judge': True, 'online': True, 'animation': True, 'website': True, 'even': True, 'powerpoint': True, 'make': True, '“': True, '”': True}, 'Negative'), ({'interpreting': True, 'course': True, 'specific': True, 'requirement': True, 'techical': True, 'support': True, 'unfortunately': True, 'function': True, 'recording': True, 'replay': True, 'collect': True, 'audio': True, 'file': True, 'zoom': True}, 'Negative'), ({'even': True, 'zoom': True, 'still': True, 'need': True, 'break': True}, 'Negative'), ({'sure': True}, 'Positive'), ({\"n't\": True, 'know': True}, 'Positive'), ({'facilitate': True, 'interaction': True, 'teacher': True, 'course': True, 'utmost': True, 'constantly': True, 'ask': True, 'student': True, 'question': True, 'especially': True, 'important': True, 'participant': True, 'mute': True, 'voice': True, 'switch': True, 'screen': True}, 'Negative'), ({}, 'Positive'), ({'include': True, 'interaction': True, 'like': True, 'discussion': True, 'poll': True}, 'Negative'), ({'utilize': True, 'teaching': True, 'equipment': True, 'school': True}, 'Negative')]\n"
     ]
    }
   ],
   "source": [
    "df = e_df.iloc[:,1].tolist()\n",
    "#print(df)\n",
    "pos_df = [df[x] for x in range(len(df)) if e_df.iloc[x,2] == 1]\n",
    "neg_df = [df[x] for x in range(len(df)) if e_df.iloc[x,2] == -1]\n",
    "\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "pos_tokens = [word_tokenize(sentence) for sentence in pos_df ]\n",
    "neg_tokens = [word_tokenize(sentence) for sentence in neg_df ]\n",
    "\n",
    "pos_cleaned_tokens_list = []\n",
    "neg_cleaned_tokens_list = []\n",
    "\n",
    "for tokens in pos_tokens:\n",
    "    pos_cleaned_tokens_list.append(remove_noise(tokens, stop_words))\n",
    "\n",
    "for tokens in neg_tokens:\n",
    "    neg_cleaned_tokens_list.append(remove_noise(tokens, stop_words))\n",
    "\n",
    "all_pos_words = get_all_words(pos_cleaned_tokens_list)\n",
    "\n",
    "freq_dist_pos = FreqDist(all_pos_words)\n",
    "print(freq_dist_pos.most_common(10))\n",
    "\n",
    "positive_tokens_for_model = get_sentence_for_model(pos_cleaned_tokens_list)\n",
    "negative_tokens_for_model = get_sentence_for_model(neg_cleaned_tokens_list)\n",
    "\n",
    "positive_dataset = [(sentence_dict, \"Positive\") for sentence_dict in positive_tokens_for_model]\n",
    "\n",
    "negative_dataset = [(sentence_dict, \"Negative\") for sentence_dict in negative_tokens_for_model]\n",
    "\n",
    "dataset = positive_dataset + negative_dataset\n",
    "\n",
    "\n",
    "random.shuffle(dataset)\n",
    "\n",
    "train_data = dataset[:220]\n",
    "test_data = dataset[220:]\n",
    "print(len(train_data))\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5049fcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "p_df = pd.read_csv('Good features.csv', header = 0, nrows = 900)\n",
    "n_df = pd.read_csv('Improvement.csv', header = 0, nrows = 700)\n",
    "\n",
    "# English\n",
    "p_e_df = p_df.copy()\n",
    "p_e_index = [x for x in range(len(p_df)) if is_contain_chinese(str(p_df.iloc[x, 0]))]\n",
    "p_e_df.drop(p_e_index, inplace=True)\n",
    "#print(p_e_df)\n",
    "\n",
    "# Hybrid\n",
    "p_h_df = p_df.copy()\n",
    "p_h_index = [x for x in range(len(p_df)) if not (is_contain_english(str(p_df.iloc[x, 0])) and is_contain_chinese(str(p_df.iloc[x, 0]))) ]\n",
    "p_h_df.drop(p_h_index, inplace=True)\n",
    "#print(p_h_index)\n",
    "\n",
    "# Chinese\n",
    "p_c_df = p_df.copy()\n",
    "p_c_index = [x for x in range(len(p_df)) if is_contain_english(str(p_df.iloc[x, 0]))]\n",
    "p_c_df.drop(p_c_index, inplace=True)\n",
    "#print(p_c_index)\n",
    "\n",
    "#print(len(p_e_df))\n",
    "\n",
    "# English\n",
    "n_e_df = n_df.copy()\n",
    "n_e_index = [x for x in range(len(n_df)) if is_contain_chinese(str(n_df.iloc[x, 0]))]\n",
    "n_e_df.drop(n_e_index, inplace=True)\n",
    "#print(n_e_df)\n",
    "\n",
    "# Hybrid\n",
    "n_h_df = n_df.copy()\n",
    "n_h_index = [x for x in range(len(n_df)) if not (is_contain_english(str(n_df.iloc[x, 0])) and is_contain_chinese(str(n_df.iloc[x, 0]))) ]\n",
    "n_h_df.drop(n_h_index, inplace=True)\n",
    "#print(n_h_index)\n",
    "\n",
    "# Chinese\n",
    "n_c_df = n_df.copy()\n",
    "n_c_index = [x for x in range(len(n_df)) if is_contain_english(str(n_df.iloc[x, 0]))]\n",
    "n_c_df.drop(n_c_index, inplace=True)\n",
    "#print(n_c_index)\n",
    "\n",
    "#print(len(n_e_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "50e3acd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('lecture', 123), ('time', 106), ('student', 100), ('good', 93), ('course', 89), ('question', 88), ('online', 85), ('video', 83), ('class', 78), ('easy', 65)]\n",
      "1214\n",
      "900\n",
      "164\n",
      "164\n"
     ]
    }
   ],
   "source": [
    "pos_df = p_e_df.iloc[:,0].tolist()\n",
    "neg_df = n_e_df.iloc[:,0].tolist()\n",
    "#print(pos_df)\n",
    "#print(neg_df)\n",
    "\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "pos_tokens = [word_tokenize(sentence) for sentence in pos_df ]\n",
    "neg_tokens = [word_tokenize(sentence) for sentence in neg_df ]\n",
    "\n",
    "pos_cleaned_tokens_list = []\n",
    "neg_cleaned_tokens_list = []\n",
    "\n",
    "for tokens in pos_tokens:\n",
    "    pos_cleaned_tokens_list.append(remove_noise(tokens, stop_words))\n",
    "\n",
    "for tokens in neg_tokens:\n",
    "    neg_cleaned_tokens_list.append(remove_noise(tokens, stop_words))\n",
    "\n",
    "all_pos_words = get_all_words(pos_cleaned_tokens_list)\n",
    "\n",
    "freq_dist_pos = FreqDist(all_pos_words)\n",
    "print(freq_dist_pos.most_common(10))\n",
    "\n",
    "positive_tokens_for_model = get_sentence_for_model(pos_cleaned_tokens_list)\n",
    "negative_tokens_for_model = get_sentence_for_model(neg_cleaned_tokens_list)\n",
    "\n",
    "positive_dataset = [(sentence_dict, \"Positive\") for sentence_dict in positive_tokens_for_model]\n",
    "\n",
    "negative_dataset = [(sentence_dict, \"Negative\") for sentence_dict in negative_tokens_for_model]\n",
    "\n",
    "dataset = positive_dataset + negative_dataset\n",
    "\n",
    "\n",
    "random.shuffle(dataset)\n",
    "for data in dataset:\n",
    "    if len(data[0]) == 0:\n",
    "        dataset.remove(data)\n",
    "    if len(data[0]) == 1:\n",
    "        if data[0] == {'none': True} or data[0] == {'nil': True} or data[0] == {'nothing': True} or data[0] == {'nope': True} or data[0] == {'N/A': True} or data[0] == {'n/a': True}:\n",
    "            dataset.remove(data)\n",
    "print(len(dataset))\n",
    "train_data = dataset[:900]\n",
    "random.shuffle(train_data)\n",
    "dev_test_data = dataset[850:1050]\n",
    "random.shuffle(dev_test_data)\n",
    "test_data = dataset[1050:]\n",
    "print(len(train_data))\n",
    "print(len(test_data))\n",
    "#print(test_data)\n",
    "'''\n",
    "for test in test_data:\n",
    "    if len(test[0]) == 1:\n",
    "        if test[0] == {'none': True} or test[0] == {'nil': True} or test[0] == {'nothing': True} or test[0] == {'nope': True} or test[0] == {'N/A': True}:\n",
    "            test_data.remove(test)\n",
    "'''\n",
    "print(len(test_data))\n",
    "#print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6df912eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.795\n",
      "({'like': True, 'normal': True, 'class': True, 'sometimes': True, 'good': True, 'cuz': True, 'may': True, 'want': True, 'spend': True, 'time': True, 'think': True, 'question': True, 'along': True, 'turn': True, 'column': True, 'microphone': True, 'real': True, 'hard': True, 'achieve': True, 'however': True, 'discuss': True, 'zoom': True}, 'Positive')\n",
      "({'video': True, 'website': True, 'like': True, 'youtube': True, 'share': True}, 'Positive')\n",
      "({'n/a': True}, 'Negative')\n",
      "({'appraisal': True, 'method': True, 'become': True, 'presentation': True, 'help': True, 'exercise': True, 'cooperation': True, 'expression': True, 'ability': True}, 'Positive')\n",
      "({}, 'Negative')\n",
      "({'timely': True, 'feedback': True, 'communication': True, 'prof': True, 'student': True}, 'Positive')\n",
      "({'perform': True, 'online': True, 'talk': True, 'let': True, 'us': True, 'know': True, 'stuff': True}, 'Positive')\n",
      "({'mate': True, 'system': True, 'cripple': True, 'online': True, 'teaching': True, 'students': True, 'reluctant': True, 'open': True, 'camera': True, 'therefore': True, 'embarassing': True, 'go': True, 'breakout': True, 'room': True, 'discus': True, 'people': True, 'ca': True, \"n't\": True, 'see': True}, 'Negative')\n",
      "({'paricipation': True}, 'Negative')\n",
      "({'n': True}, 'Negative')\n",
      "({'give': True, 'example': True}, 'Positive')\n",
      "({}, 'Negative')\n",
      "({'frankie': True, 'teach': True, 'course': True}, 'Negative')\n",
      "({'hard': True, 'face': True, 'even': True}, 'Positive')\n",
      "({'teacher': True, 'spend': True, 'time': True, 'explain': True, 'knowledge': True, 'others': True}, 'Positive')\n",
      "({'interactive': True, 'time': True, 'professor': True}, 'Positive')\n",
      "({'comment': True, 'rating': True, 'lecturer': True, 'mr.hugo': True, 'wai': True, 'leung': True, 'mak': True, 'take': True, 'whole': True, 'course': True, 'online': True, 'learning': True}, 'Negative')\n",
      "({'zoom': True, 'crash': True, 'recording': True, 'may': True, 'lose': True, 'ppt': True}, 'Negative')\n",
      "({}, 'Negative')\n",
      "({'bad': True, 'lecturer': True}, 'Positive')\n",
      "({'frankie': True, 'intend': True, 'adapt': True, 'variation': True, 'teach': True, 'method': True, 'assist': True, 'teaching': True, 'tool': True, 'online': True, 'give': True, 'flexibility': True, 'try': True}, 'Positive')\n",
      "({'much': True, 'convenient': True, 'student': True, 'access': True, 'assignment': True, 'require': True, 'cuhk': True, 'vpn': True}, 'Positive')\n",
      "({'normal': True, 'lecture': True, 'hard': True, 'understand': True, 'material': True, 'however': True, 'online': True, 'participant': True, 'small': True, 'easy': True, 'teacher': True, 'engage': True, 'others': True, 'student': True, 'therefore': True}, 'Positive')\n",
      "({'good': True}, 'Negative')\n",
      "({'interaction': True, 'teacher': True, 'student': True, 'enhance': True}, 'Negative')\n",
      "({}, 'Negative')\n",
      "({'nil': True}, 'Positive')\n",
      "({'professor': True, 'suitable': True, 'online': True, 'teaching': True}, 'Positive')\n",
      "({'interaction': True, 'student': True}, 'Positive')\n",
      "({'time': True, 'lab': True, 'exercise': True, 'home': True, 'efficient': True, 'work': True}, 'Positive')\n",
      "({'comprehensive': True, 'online': True, 'information': True, 'resource': True, 'could': True, 'use': True, 'system': True, 'course': True, 'efficient': True, 'presentation': True}, 'Positive')\n",
      "({'recording': True}, 'Negative')\n",
      "({'interaction': True}, 'Positive')\n",
      "({'still': True, 'demonstrate': True, 'basic': True, 'knowledge': True, 'others': True, 'like': True, 'use': True, 'spreadsheet': True, 'internet': True, 'security': True, 'screen': True, 'share': True, 'teacher': True}, 'Positive')\n",
      "({'group': True, 'discuss': True, 'easy': True}, 'Positive')\n",
      "({'good': True}, 'Negative')\n",
      "({'want': True, 'go': True, 'back': True, 'campus': True}, 'Negative')\n",
      "({'tutorials': True, 'tas': True, 'record': True, 'appropriate': True, 'quality': True}, 'Negative')\n",
      "({'wish': True, 'ta': True, 'send': True, 'us': True, 'back': True, 'pdf': True, 'graded': True, 'homework': True, 'already': True, 'note': True, 'explanation': True, 'wrong': True, 'answer': True}, 'Negative')\n",
      "({'students': True, 'revise': True, 'material': True, 'home': True, 'good': True, 'build': True, 'solid': True, 'foundation': True, 'basic': True, 'concept': True, 'course': True, 'sugge': True, 'othersst': True, 'even': True, 'class': True, 'resume': True, 'teacher': True, 'consider': True, 'post': True, 'lecture': True, 'online': True}, 'Positive')\n",
      "({'screen': True, 'drawing': True, 'pretty': True, 'good': True}, 'Positive')\n",
      "Accuracy is: 0.7804878048780488\n",
      "Most Informative Features\n",
      "                     see = True           Positi : Negati =     13.8 : 1.0\n",
      "                 receive = True           Negati : Positi =     12.4 : 1.0\n",
      "                   maybe = True           Negati : Positi =     11.5 : 1.0\n",
      "                 however = True           Negati : Positi =     11.3 : 1.0\n",
      "                  change = True           Negati : Positi =     10.6 : 1.0\n",
      "                    easy = True           Positi : Negati =     10.0 : 1.0\n",
      "              connection = True           Negati : Positi =      9.7 : 1.0\n",
      "               recording = True           Positi : Negati =      9.1 : 1.0\n",
      "                    like = True           Negati : Positi =      9.1 : 1.0\n",
      "                 instead = True           Negati : Positi =      8.7 : 1.0\n",
      "None\n",
      "({'class': True, 'invite': True, 'many': True, 'prof': True, 'manage': True, 'othersr': True, 'give': True, 'speech': True}, 'Positive')\n",
      "({'need': True, 'redio': True}, 'Negative')\n",
      "({'chance': True, 'encounter': True, 'problem': True}, 'Positive')\n",
      "({'easy': True, 'review': True, 'since': True, 'panopto': True, 'video': True, 'in-campus': True, 'teaching': True, 'lack': True, 'support': True, 'difficult': True, 'professor': True, 'talk': True, 'class': True}, 'Positive')\n",
      "({'clear': True, 'explanation': True, 'different': True, 'topic': True, 'optical': True, 'communication': True, 'dig': True, 'really': True, 'deep': True, 'kind': True, 'difficult': True, 'understood': True, 'amount': True, 'powerpoint': True, 'material': True, 'slightly': True, 'adjust': True, 'rush': True, 'complete': True, 'esp': True, 'time': True, 'teaching': True, 'leave': True, 'overall': True, 'excellent': True, 'course': True, 'ierg': True, 'student': True, 'increase': True, 'exposure': True, 'telecommunication': True, 'tech': True, 'market': True, 'seminar': True, 'external': True, 'speaker': True}, 'Positive')\n",
      "({'course': True, 'video-taped': True, 'make': True, 'possible': True, 'revision': True, 'useful': True, 'skill': True, 'demonstrate': True, 'lecture': True, 'note': True, 'videos': True}, 'Positive')\n",
      "({}, 'Negative')\n",
      "({'interaction': True, 'prof': True}, 'Positive')\n",
      "({'interactive': True}, 'Positive')\n",
      "({'lectures': True, 'record': True, 'online': True, 'pandemic': True, 'much': True, 'difference': True, 'overall': True, 'teaching': True, 'experience': True, 'quite': True, 'good': True}, 'Positive')\n",
      "({'lecture': True, 'slide': True, 'well-organized': True, 'consistent': True, 'line': True, 'thinking': True, 'professor': True, 'explain': True, 'thing': True, 'quite': True, 'clearly': True, 'many': True, 'helpful': True, 'example': True, 'course': True, 'friendly': True, 'little': True, 'previous': True, 'background': True, 'security': True, 'feel': True, 'difficulty': True, 'follow': True, 'assignment': True, 'well': True, 'design': True, 'lot': True, 'instruction': True, 'help': True, 'think': True, 'grading': True, 'also': True, 'careful': True, 'way': True, 'locate': True, 'problem': True, 'responsive': True, 'question': True, 'difficulities': True, 'matter': True, 'email': True, 'post': True, 'piazza': True}, 'Positive')\n",
      "({'good': True}, 'Negative')\n",
      "({'data': True, 'easily': True, 'accessible': True, 'example': True, 'assignment': True, 'longe': True, 'othersr': True, 'require': True, 'cuhk': True, 'vpn': True, 'access': True}, 'Positive')\n",
      "({'video': True, 'renew': True, 'smooth': True, 'real': True, 'lecture': True}, 'Negative')\n",
      "({'difficulty': True, 'ask': True, 'face': True, 'problem': True, 'lesson': True}, 'Negative')\n",
      "({'well': True}, 'Positive')\n",
      "({}, 'Negative')\n",
      "({'provide': True, 'lecture': True, 'recording': True}, 'Negative')\n",
      "({'remained': True, 'course': True, 'hold': True, 'instead': True, 'cancel': True}, 'Positive')\n",
      "({'willing': True, 'provide': True, 'course': True, 'recording': True}, 'Negative')\n",
      "({'course': True, 'mainly': True, 'discussion': True, 'easily': True, 'suit': True, 'online': True, 'teaching': True}, 'Positive')\n",
      "({'video': True, 'smooth': True, 'enough': True}, 'Negative')\n",
      "({'student': True, 'active': True, 'ask': True, 'question': True, 'attend': True, 'discussion': True, 'channel': True, 'like': True, 'chatroom': True, 'ureply': True}, 'Positive')\n",
      "({'use': True, 'breakout': True, 'room': True}, 'Negative')\n",
      "({'none': True}, 'Positive')\n",
      "({'good': True}, 'Negative')\n",
      "({'hand': True, 'drawn': True, 'illustration': True, 'show': True, 'class': True, 'improve': True, 'understand': True, 'material': True}, 'Positive')\n",
      "({'lecture': True, 'still': True, 'run': True, 'smoothly': True}, 'Positive')\n",
      "({'video': True, 'share': True}, 'Negative')\n",
      "({'lecturer': True, 'use': True, 'handwriting': True, 'draw': True, 'enhance': True, 'teaching': True}, 'Positive')\n",
      "({'really': True, 'miss': True, 'whiteboard': True}, 'Negative')\n",
      "({'overview': True, 'course': True, 'viedeo': True, 'class': True, 'case': True, 'misunderstanding': True, 'confusion': True}, 'Positive')\n",
      "({}, 'Negative')\n",
      "({'’': True, 'undoubtedly': True, 'cool': True, 'online': True, 'teach': True, 'almost': True, 'twin': True, 'video': True, 'record': True, 'enhance': True, 'flexibility': True, 'student': True, 'study': True, 'plan': True, 'nothing': True, 'complain': True}, 'Positive')\n",
      "({'content': True, 'class': True, 'much': True, 'maybe': True, 'ge': True, 'otherst': True, 'vedio': True, 'reviev': True, 'prepare': True, 'exam': True}, 'Positive')\n",
      "({}, 'Negative')\n",
      "0.7804878048780488\n"
     ]
    }
   ],
   "source": [
    "classifier = NaiveBayesClassifier.train(train_data)\n",
    "print(classify.accuracy(classifier, dev_test_data))\n",
    "for i in dev_test_data:\n",
    "    if classifier.classify(i[0]) != i[1]:\n",
    "        print(i)\n",
    "print(\"Accuracy is:\", classify.accuracy(classifier, test_data))\n",
    "print(classifier.show_most_informative_features(10))\n",
    "acc = 0\n",
    "ans = \"\"\n",
    "for i in test_data:\n",
    "    if i[0] == {}:\n",
    "        ans = \"Positive\"\n",
    "    else:\n",
    "        ans = classifier.classify(i[0])\n",
    "    if  ans == i[1]:\n",
    "        acc = acc + 1\n",
    "    else:\n",
    "        print(i)\n",
    "print(acc/(len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a4c4e366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547\n",
      "766\n",
      "1287\n",
      "731\n",
      "0.425019425019425\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "acc = 0\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "for x in dataset:\n",
    "    res = sia.polarity_scores(str(x))\n",
    "    comp = res['compound']\n",
    "    del res['compound']\n",
    "    #print(x, '\\n', 'result:', max(res, key=res.get),'\\n', 'compound:', comp, '\\n')\n",
    "    if (max(res, key=res.get) == \"pos\" and x[1] == \"Positive\"): #or (max(res, key=res.get) == \"neu\" and x[1] == \"Negative\"):\n",
    "        acc = acc + 1\n",
    "        #print(x)\n",
    "print(acc)\n",
    "print(len(pos_df))\n",
    "print(len(dataset))\n",
    "count = 0\n",
    "for a in dataset:\n",
    "    if a[1] == \"Positive\":\n",
    "        count = count + 1\n",
    "print(count)\n",
    "print(acc/len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5bdce293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8407310704960835\n",
      "0.6540469973890339\n",
      "none \n",
      " Negative\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for x in pos_df:\n",
    "    #print(x)\n",
    "    test_sen = x\n",
    "    test_tokens = remove_noise(word_tokenize(test_sen))\n",
    "    #print(test_sen,'\\n', classifier.classify(dict([token, True] for token in test_tokens)))\n",
    "    if classifier.classify(dict([token, True] for token in test_tokens)) == \"Positive\":\n",
    "        count = count + 1\n",
    "print(count/len(pos_df))\n",
    "\n",
    "count = 0\n",
    "for x in neg_df:\n",
    "    #print(x)\n",
    "    test_sen = x\n",
    "    test_tokens = remove_noise(word_tokenize(test_sen))\n",
    "    #print(test_sen,'\\n', classifier.classify(dict([token, True] for token in test_tokens)))\n",
    "    if classifier.classify(dict([token, True] for token in test_tokens)) == \"Negative\":\n",
    "        count = count + 1\n",
    "print(count/len(pos_df))\n",
    "\n",
    "test_sen = \"none\"\n",
    "test_tokens = remove_noise(word_tokenize(test_sen))\n",
    "\n",
    "print(test_sen,'\\n', classifier.classify(dict([token, True] for token in test_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "692ac080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(':)', 3691), (':-)', 701), (':d', 658), ('thanks', 388), ('follow', 357), ('love', 333), ('...', 290), ('good', 283), ('get', 263), ('thank', 253)]\n",
      "Accuracy is: 0.996\n",
      "Most Informative Features\n",
      "                      :( = True           Negati : Positi =   2080.2 : 1.0\n",
      "                      :) = True           Positi : Negati =   1637.1 : 1.0\n",
      "                     sad = True           Negati : Positi =     34.4 : 1.0\n",
      "                follower = True           Positi : Negati =     22.2 : 1.0\n",
      "                     bam = True           Positi : Negati =     21.9 : 1.0\n",
      "                followed = True           Negati : Positi =     20.7 : 1.0\n",
      "                  arrive = True           Positi : Negati =     18.7 : 1.0\n",
      "           @justinbieber = True           Negati : Positi =     18.2 : 1.0\n",
      "               community = True           Positi : Negati =     15.4 : 1.0\n",
      "                 welcome = True           Positi : Negati =     13.3 : 1.0\n",
      "None\n",
      "everything is good \n",
      " Positive\n"
     ]
    }
   ],
   "source": [
    "# tweet training set\n",
    "\n",
    "positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
    "\n",
    "positive_tweet_tokens = twitter_samples.tokenized('positive_tweets.json')\n",
    "negative_tweet_tokens = twitter_samples.tokenized('negative_tweets.json')\n",
    "\n",
    "positive_cleaned_tokens_list = []\n",
    "negative_cleaned_tokens_list = []\n",
    "\n",
    "for tokens in positive_tweet_tokens:\n",
    "    positive_cleaned_tokens_list.append(remove_noise(tokens, stop_words))\n",
    "\n",
    "for tokens in negative_tweet_tokens:\n",
    "    negative_cleaned_tokens_list.append(remove_noise(tokens, stop_words))\n",
    "\n",
    "all_pos_words = get_all_words(positive_cleaned_tokens_list)\n",
    "\n",
    "freq_dist_pos = FreqDist(all_pos_words)\n",
    "print(freq_dist_pos.most_common(10))\n",
    "\n",
    "positive_tokens_for_model = get_sentence_for_model(positive_cleaned_tokens_list)\n",
    "negative_tokens_for_model = get_sentence_for_model(negative_cleaned_tokens_list)\n",
    "\n",
    "positive_dataset = [(tweet_dict, \"Positive\") for tweet_dict in positive_tokens_for_model]\n",
    "\n",
    "negative_dataset = [(tweet_dict, \"Negative\") for tweet_dict in negative_tokens_for_model]\n",
    "\n",
    "dataset = positive_dataset + negative_dataset\n",
    "\n",
    "random.shuffle(dataset)\n",
    "\n",
    "train_data = dataset[:7000]\n",
    "test_data = dataset[7000:]\n",
    "\n",
    "classifier = NaiveBayesClassifier.train(train_data)\n",
    "\n",
    "print(\"Accuracy is:\", classify.accuracy(classifier, test_data))\n",
    "\n",
    "print(classifier.show_most_informative_features(10))\n",
    "\n",
    "custom_tweet = \"everything is good\"\n",
    "\n",
    "custom_tokens = remove_noise(word_tokenize(custom_tweet))\n",
    "\n",
    "print(custom_tweet, '\\n', classifier.classify(dict([token, True] for token in custom_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd596221",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
